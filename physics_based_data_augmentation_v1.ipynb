{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa58a1c",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef379545",
   "metadata": {},
   "source": [
    "## Weighted MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd457a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_weighted_mse(y_pred, y, loss_weights):\n",
    "    y_diff_squared = (y - y_pred)**2\n",
    "    y_diff_squared_weighted = torch.einsum('ijkl,j->ijkl', y_diff_squared, exp_mse_weights)\n",
    "    weighted_mse = torch.mean(y_diff_squared_weighted)\n",
    "    return weighted_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce745e0",
   "metadata": {},
   "source": [
    "## Generate weights for exponential MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exp_weights(T, alpha):\n",
    "    decay_length = 20.0\n",
    "    augmentation_container = torch.linspace(0, 1, steps=T)\n",
    "    augmentation_parameter = torch.linspace(0, alpha, steps=T)\n",
    "    exp_mse_weights_unflipped = torch.exp(-decay_length * augmentation_container)\n",
    "    exp_mse_weights = torch.flip(exp_mse_weights_unflipped, dims=[0])\n",
    "    return exp_mse_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c7721",
   "metadata": {},
   "source": [
    "## PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psf_kernel(sigma=1.0, psf_size=15):\n",
    "\n",
    "    psf_kernel = torch.zeros(psf_size, psf_size)\n",
    "    psf_center = psf_size // 2\n",
    "    for x in range(psf_size):\n",
    "        for y in range(psf_size):\n",
    "            psf_kernel[x, y] = torch.exp(torch.tensor(-((x - psf_center) ** 2 + (y - psf_center) ** 2) / (2 * sigma ** 2)))\n",
    "    psf_kernel /= psf_kernel.sum()\n",
    "\n",
    "    return psf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_kernel = generate_psf_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f36172",
   "metadata": {},
   "source": [
    "## Define CoordConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordConv2DLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        _, _, height, width = input_tensor.size()\n",
    "\n",
    "        # Create x and y coordinate grids\n",
    "        xx_channel = torch.arange(width).view(1, 1, 1, width).expand(1, 1, height, width).float() / (width - 1)\n",
    "        yy_channel = torch.arange(height).view(1, 1, height, 1).expand(1, 1, height, width).float() / (height - 1)\n",
    "\n",
    "        # Concatenate the coordinate channels to the input tensor\n",
    "        output_tensor = torch.cat([xx_channel, yy_channel], dim=1)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec369ae",
   "metadata": {},
   "source": [
    "## Define FourierConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdcfd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierConv2DLayer(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, num_input_channels, height, width = x.size()\n",
    "\n",
    "        # Generate frequencies\n",
    "        base_frequency = 2\n",
    "        exponent_value = torch.arange(L)\n",
    "        frequencies = torch.pow(torch.tensor(base_frequency), exponent_value).float()\n",
    "\n",
    "        # Apply Fourier basis functions\n",
    "        fourier_features = [torch.sin(frequencies[j] * torch.pi * x) for j in range(L)]\n",
    "        fourier_features += [torch.cos(frequencies[j] * torch.pi * x) for j in range(L)]\n",
    "\n",
    "        # Concatenate the Fourier features along the channel dimension\n",
    "        fourier_features = torch.cat(fourier_features, dim=1)\n",
    "\n",
    "        return fourier_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02e1ff",
   "metadata": {},
   "source": [
    "## Define InverseConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseConv2DLayer(nn.Module):\n",
    "    def __init__(self, L, num_standard_layers, max_reflectance, subsample_factor=2, use_fourier=True):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "        self.num_fourier_channels = 2\n",
    "        self.num_standard_layers = num_standard_layers\n",
    "        self.use_fourier = use_fourier\n",
    "        \n",
    "        self.upsample_layer = nn.Upsample(scale_factor=subsample_factor, mode='nearest')\n",
    "        self.coordinate_layer = CoordConv2DLayer()\n",
    "        self.fourier_layer = FourierConv2DLayer(L)\n",
    "            \n",
    "        if self.use_fourier:\n",
    "            self.fourier_layer = FourierConv2DLayer(L)\n",
    "            self.num_fourier_channels = 4*L\n",
    "        \n",
    "        self.standard_hidden_layers = nn.ModuleList(\n",
    "        [nn.Conv2d(self.num_fourier_channels, self.num_fourier_channels, kernel_size=3, padding='same') for _ in range(num_standard_layers)]\n",
    "        )\n",
    "        \n",
    "        self.standard_output_layer = nn.Conv2d(self.num_fourier_channels, 1, kernel_size=3, padding='same')\n",
    "        self.downsample_layer = nn.MaxPool2d(kernel_size=subsample_factor, stride=subsample_factor)\n",
    "        \n",
    "        # Initialize weights with He uniform variance scaling initializer\n",
    "        for layer in self.standard_hidden_layers:\n",
    "            nn.init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "            nn.init.zeros_(layer.bias)  # Initialize biases to zero\n",
    "        nn.init.kaiming_uniform_(self.standard_output_layer.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        nn.init.zeros_(self.standard_output_layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample_layer(x)\n",
    "        output_coordinate = self.coordinate_layer(x)\n",
    "        \n",
    "        if self.use_fourier:\n",
    "            output_fourier = self.fourier_layer(output_coordinate)\n",
    "        else:\n",
    "            output_fourier = output_coordinate\n",
    "        \n",
    "        x = output_fourier\n",
    "        for layer in self.standard_hidden_layers:\n",
    "            x = nn.functional.elu(layer(x))\n",
    "        \n",
    "        output = nn.functional.softplus(self.standard_output_layer(x))\n",
    "        \n",
    "        use_sigmoidal_output = True\n",
    "        if use_sigmoidal_output:\n",
    "            output = max_reflectance * torch.sigmoid(output)\n",
    "        \n",
    "        output_downsampled = self.downsample_layer(output)\n",
    "        output_inverse = output_downsampled\n",
    "\n",
    "        return output_coordinate, output_fourier, output, output_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e4540",
   "metadata": {},
   "source": [
    "## Define Augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(original_image, augmentation_stride=1, blob_intensity=0.01, contrast_steps=2, mode=\"contrast\"):\n",
    "    \n",
    "    augmented_image = torch.zeros_like(original_image)\n",
    "    \n",
    "    if mode == \"translation\":\n",
    "        augmentation_stride = min(augmentation_stride, 19)\n",
    "        augmented_image[:, :, :, augmentation_stride:] = original_image[:, :, :, :-augmentation_stride]\n",
    "    elif mode == \"elastic\":\n",
    "        elastic_parameter = 50.0 + augmentation_stride*10.0\n",
    "        elastic_transformer = transforms.ElasticTransform(alpha=elastic_parameter)\n",
    "        augmented_image = elastic_transformer(original_image)\n",
    "    elif mode == \"blob\":\n",
    "        blob_start = augmentation_stride\n",
    "        blob_size = 5\n",
    "        blob_end = blob_start + blob_size\n",
    "        blob_tensor = torch.zeros(original_image.size())\n",
    "        blob_tensor[:, :, blob_start:blob_end, blob_start:blob_end] = blob_intensity\n",
    "        augmented_image = original_image + blob_tensor\n",
    "    elif mode == \"contrast\":\n",
    "        reflectance_max = float(torch.max(original_image).detach().numpy())\n",
    "        reflectance_axis = torch.linspace(0, reflectance_max, steps=contrast_steps)\n",
    "        reflectance_augmented = reflectance_axis[augmentation_stride-1]\n",
    "        augmented_image = torch.abs(original_image - reflectance_augmented)\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac712ef",
   "metadata": {},
   "source": [
    "## Define AugmentationConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9476eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationConv2DLayer(nn.Module):\n",
    "    def __init__(self, T):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        _, num_input_channels, height, width = x.size()\n",
    "\n",
    "        # Apply augmentation\n",
    "        augmented_features = [\n",
    "                augment_image(x, augmentation_stride=j+1, blob_intensity=alpha, contrast_steps=self.T) for j in range(self.T)\n",
    "                ]\n",
    "\n",
    "        # Concatenate the augmented features along the channel dimension\n",
    "        augmented_features = torch.cat(augmented_features, dim=1)\n",
    "\n",
    "        return augmented_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebf4f7",
   "metadata": {},
   "source": [
    "## Define Microscope CNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroscopeCNNLayer(nn.Module):\n",
    "    def __init__(self, psf_kernel):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Conv2d(1, 1, kernel_size=psf_kernel.size(0), padding='same', bias=False)\n",
    "        self.conv_layer.weight = nn.Parameter(psf_kernel.unsqueeze(0).unsqueeze(0), requires_grad=False)\n",
    "        self.intensity_layer = IntensityLayer()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_conv = self.conv_layer(x)\n",
    "        output_intensity = self.intensity_layer(output_conv)\n",
    "        output_final = output_intensity / torch.max(output_intensity)\n",
    "        return output_conv, output_intensity, output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntensityLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.square(torch.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c350b0a",
   "metadata": {},
   "source": [
    "## Define PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631440bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, L, T, alpha, num_standard_layers, max_reflectance, subsample_factor, psf_kernel, use_fourier=True):\n",
    "        super().__init__()\n",
    "        self.inverse_layer = InverseConv2DLayer(L, num_standard_layers, max_reflectance, subsample_factor, use_fourier=use_fourier)\n",
    "        self.augmentation_layer = AugmentationConv2DLayer(T)\n",
    "        self.forward_layer = MicroscopeCNNLayer(psf_kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_coordinate, output_fourier, output, output_inverse = self.inverse_layer(x)\n",
    "        output_augmentation = self.augmentation_layer(output_inverse, alpha)\n",
    "        \n",
    "        batch_size, num_augmentations, height, width = output_augmentation.size()\n",
    "        \n",
    "        output_conv = torch.zeros_like(output_augmentation)\n",
    "        output_intensity = torch.zeros_like(output_augmentation)\n",
    "        output_final = torch.zeros_like(output_augmentation)\n",
    "        \n",
    "        for t in range(self.augmentation_layer.T):\n",
    "            output_conv_t, output_intensity_t, output_final_t = self.forward_layer(output_augmentation[:,t,:,:].unsqueeze(0))\n",
    "            output_conv[:,t,:,:] = output_conv_t\n",
    "            output_intensity[:,t,:,:] = output_intensity_t\n",
    "            output_final[:,t,:,:] = output_final_t\n",
    "        \n",
    "        return output, output_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe2cb2",
   "metadata": {},
   "source": [
    "## Sensor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d695854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_func(image, noise_level=0.1, subsample_factor=2):\n",
    "    # Generate random noise with the same shape as the input image\n",
    "    noise = noise_level * torch.randn_like(image)\n",
    "\n",
    "    # Add the scaled noise to the original image\n",
    "    noisy_image = image + noise\n",
    "    \n",
    "    # Apply subsampling using a pooling operation (e.g., MaxPool2d)\n",
    "    subsampled_image = nn.functional.max_pool2d(noisy_image, kernel_size=subsample_factor, stride=subsample_factor)\n",
    "    \n",
    "    # Clip the values to ensure they are within the valid range (0, 1)\n",
    "    sensor_image = torch.clamp(subsampled_image, 0, 1)\n",
    "\n",
    "    return sensor_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8aceab",
   "metadata": {},
   "source": [
    "## Extract sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f6068",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "#sample_image, label = mnist_train[0]\n",
    "#sample_image, label = mnist_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd671e35",
   "metadata": {},
   "source": [
    "### Shepp Logan or Wavy Fibers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "sample_image_path = \"shepp_logan_phantom.png\"\n",
    "#sample_image_path = \"shepp_logan_phantom_complement.png\"\n",
    "#sample_image_path = \"wavy_fibers_processed.png\"\n",
    "sample_image_pil = Image.open(sample_image_path)\n",
    "sample_image_not_normalized = transform(sample_image_pil)\n",
    "sample_image = sample_image_not_normalized / torch.max(sample_image_not_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27973f65",
   "metadata": {},
   "source": [
    "## Visualize sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e96ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b74e6",
   "metadata": {},
   "source": [
    "## Construct Ground Truth Reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pixel_intensity = sample_image\n",
    "alpha = 0.01\n",
    "reflectance_ground_truth = alpha*normalized_pixel_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce274863",
   "metadata": {},
   "source": [
    "## Resize Ground Truth Reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b114bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels, height, width = reflectance_ground_truth.size()\n",
    "reflectance_ground_truth = reflectance_ground_truth.view(1, channels, height, width)\n",
    "reflectance_ground_truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef22c6",
   "metadata": {},
   "source": [
    "## Generate \"Training\" Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ddf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model_mismatch = True\n",
    "if apply_model_mismatch:\n",
    "    psf_kernel_real = generate_psf_kernel(sigma=2.0, psf_size=21)\n",
    "    microscope_model = MicroscopeCNNLayer(psf_kernel_real)\n",
    "else:\n",
    "    microscope_model = MicroscopeCNNLayer(psf_kernel)\n",
    "\n",
    "subsample_factor = 16;\n",
    "apply_sensor = True\n",
    "\n",
    "#T = 20\n",
    "T = 2\n",
    "augmentation_layer = AugmentationConv2DLayer(T)\n",
    "input_augmentation = augmentation_layer(reflectance_ground_truth, alpha)\n",
    "\n",
    "batch_size, num_augmentations, height, width = input_augmentation.size()\n",
    "training_image = torch.zeros(batch_size, num_augmentations, height//subsample_factor, width//subsample_factor)\n",
    "\n",
    "#microscope_model = MicroscopeCNNLayer(psf_kernel) \n",
    "\n",
    "use_negative = False\n",
    "\n",
    "if use_negative:\n",
    "    #_, _, microscope_image = microscope_model(reflectance_ground_truth)\n",
    "    #intensity_max = float(torch.max(microscope_image).detach().numpy())\n",
    "    #intensity_axis = torch.linspace(0, intensity_max, steps=T)\n",
    "    _, _, microscope_image_ideal = microscope_model(reflectance_ground_truth)\n",
    "    intensity_max = float(torch.max(microscope_image_ideal).detach().numpy())\n",
    "    intensity_axis = torch.linspace(0, intensity_max, steps=T)\n",
    "    \n",
    "for t in range(T):\n",
    "    if use_negative:\n",
    "        intensity_augmented = intensity_axis[t]\n",
    "        training_image_t = torch.abs(microscope_image - intensity_augmented)\n",
    "    else:\n",
    "        _, _, training_image_t = microscope_model(input_augmentation[:,t,:,:].unsqueeze(0))\n",
    "        if apply_sensor:\n",
    "            training_image_t = sensor_func(training_image_t, subsample_factor = subsample_factor)\n",
    "    training_image[:,t,:,:] = training_image_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3c2a7",
   "metadata": {},
   "source": [
    "## Check Training Image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a936c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd005adb",
   "metadata": {},
   "source": [
    "## Visualize Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, T, figsize=(15, 3))\n",
    "for t in range(T):\n",
    "    axs[t].imshow(training_image[:,t,:,:].squeeze().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_image[:,0,:,:].squeeze().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc35006",
   "metadata": {},
   "source": [
    "## Define configurations for Inverse Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 4\n",
    "num_standard_layers = 4\n",
    "max_reflectance = alpha\n",
    "use_fourier = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7a03b",
   "metadata": {},
   "source": [
    "## Network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae46f6",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn_model_dummy = PINN(L, T, alpha, num_standard_layers, max_reflectance, subsample_factor, psf_kernel, use_fourier)\n",
    "_, channels_dummy, height_dummy, width_dummy = training_image.size()\n",
    "summary(pinn_model_dummy, input_size=(channels_dummy, height_dummy, width_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b11a02",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PINN model\n",
    "pinn_model = PINN(L, T, alpha, num_standard_layers, max_reflectance, subsample_factor, psf_kernel, use_fourier)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(pinn_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Set up the exponential learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=np.exp(np.log(5e-6 / 1e-4) / 10000))\n",
    "\n",
    "# Set the regularization strengths (lambdas)\n",
    "lambda_boundary = 0.25\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10000\n",
    "\n",
    "# Define list to store loss values\n",
    "loss_list = []\n",
    "\n",
    "# Define list to store intermediate outputs for reflectance\n",
    "intermediate_output_reflectance = []\n",
    "\n",
    "# Generate exp mse loss weights\n",
    "use_exp_mse_weights = True\n",
    "if use_exp_mse_weights:\n",
    "    exp_mse_weights = generate_exp_weights(T, alpha)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    iter_reflectance, iter_image = pinn_model(training_image)\n",
    "\n",
    "    # Calculate the mse loss\n",
    "    if use_exp_mse_weights:\n",
    "        loss_mse = loss_weighted_mse(iter_image, training_image, exp_mse_weights)\n",
    "    else:\n",
    "        loss_mse = criterion(iter_image, training_image)\n",
    "    \n",
    "    # Calculate the boundary regularization loss\n",
    "    loss_boundary = lambda_boundary * (\n",
    "          torch.square(iter_image[:, :, 0, :] - 0).mean()\n",
    "        + torch.square(iter_image[:, :, -1, :] - 0).mean()\n",
    "        + torch.square(iter_image[:, :, :, 0] - 0).mean()\n",
    "        + torch.square(iter_image[:, :, :, -1] - 0).mean()\n",
    "    )\n",
    "    \n",
    "    # Calculate the total loss\n",
    "    loss_total = loss_mse + loss_boundary\n",
    "    loss = loss_total\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print training statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b1abf",
   "metadata": {},
   "source": [
    "## Display Loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f13590",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reflectance, _ = pinn_model(training_image)\n",
    "_, _, predicted_image = microscope_model(predicted_reflectance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73203d2f",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_plot = reflectance_ground_truth.squeeze().numpy()\n",
    "predicted_reflectance_plot = predicted_reflectance.squeeze().detach().numpy()\n",
    "\n",
    "if use_negative:\n",
    "    microscope_output_plot = microscope_image.squeeze().detach().numpy()\n",
    "else:\n",
    "    unaugmented_output_plot = training_image[:,0,:,:].squeeze().detach().numpy()\n",
    "\n",
    "fig, (ax_1, ax_2, ax_3) = plt.subplots(1, 3, figsize=(14, 6))\n",
    "fig.suptitle(\"Summary\")\n",
    "\n",
    "ax_1.imshow(ground_truth_plot, cmap='gray')\n",
    "ax_1.set_ylabel('Y-coordinate')\n",
    "ax_1.set_title('Ground Truth')\n",
    "\n",
    "if use_negative:\n",
    "    ax_2.imshow(microscope_output_plot, cmap='gray')\n",
    "    ax_2.set_title('Microscope Output')\n",
    "else:\n",
    "    ax_2.imshow(unaugmented_output_plot, cmap='gray')\n",
    "    ax_2.set_title('Unaugmented Output')\n",
    "ax_2.set_xlabel('X-coordinate')\n",
    "\n",
    "ax_3.imshow(predicted_reflectance_plot, cmap='gray')\n",
    "ax_3.set_title('PINN Prediction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c42364",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_1, ax_2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "fig.suptitle(\"Visualize Reflectance\")\n",
    "\n",
    "ax_1.imshow(ground_truth_plot, cmap='gray')\n",
    "ax_1.set_xlabel('X-coordinate')\n",
    "ax_1.set_ylabel('Y-coordinate')\n",
    "ax_1.set_title('Ground Truth')\n",
    "\n",
    "ax_2.imshow(predicted_reflectance_plot, cmap='gray')\n",
    "ax_2.set_title('PINN Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31295d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18476f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reflectance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_image.squeeze().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = torch.meshgrid(torch.arange(predicted_reflectance_plot.shape[0]), torch.arange(predicted_reflectance_plot.shape[1]))\n",
    "\n",
    "fig= plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Surface plot of the Predicted Reflectance\")\n",
    "\n",
    "ax_1 = fig.add_subplot(111, projection='3d')\n",
    "surface = ax_1.plot_surface(x, y, predicted_reflectance_plot, cmap='viridis')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Surface plot of the Ground Truth\")\n",
    "\n",
    "ax_1 = fig.add_subplot(111, projection='3d')\n",
    "surface = ax_1.plot_surface(x, y, ground_truth_plot, cmap='viridis')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a932c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_plot = predicted_reflectance_plot - ground_truth_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5590081",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Surface plot of the Error\")\n",
    "\n",
    "ax_1 = fig.add_subplot(111, projection='3d')\n",
    "surface = ax_1.plot_surface(x, y, error_plot, cmap='viridis')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(error_plot)\n",
    "plt.xlabel('error value')\n",
    "plt.ylabel('frequency')\n",
    "plt.title(\"Error Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add41847",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(error_plot).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
