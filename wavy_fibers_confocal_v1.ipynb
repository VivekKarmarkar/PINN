{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625bd56b",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfff0b8",
   "metadata": {},
   "source": [
    "## Define Image transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4284693",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f3deb",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_image_path = \"shepp_logan_phantom.png\"\n",
    "#sample_image_path = \"shepp_logan_phantom_complement.png\"\n",
    "sample_image_path = \"wavy_fibers_processed.png\"\n",
    "#sample_image_path = \"wavy_fibers_processed_2.png\"\n",
    "sample_image_pil = Image.open(sample_image_path)\n",
    "sample_image = transform(sample_image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "#sample_image, label = mnist_train[0]\n",
    "#sample_image, label = mnist_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a03a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e338821",
   "metadata": {},
   "source": [
    "## Normalize pixel intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = sample_image / torch.max(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f721287",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637500f8",
   "metadata": {},
   "source": [
    "## Surface plot of pixel intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ba29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_plot = sample_image.squeeze().numpy()\n",
    "\n",
    "xp, yp = torch.meshgrid(torch.arange(sample_image_plot.shape[0]), torch.arange(sample_image_plot.shape[1]))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xp, yp, sample_image_plot, cmap='viridis', alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Pixel Intensity Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06642d2",
   "metadata": {},
   "source": [
    "## Construct Ground Truth Reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pixel_intensity = sample_image\n",
    "alpha = 0.01\n",
    "reflectance_ground_truth = alpha*normalized_pixel_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ad63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectance_ground_truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227d0be",
   "metadata": {},
   "source": [
    "## Resize Ground Truth Reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels, height, width = reflectance_ground_truth.size()\n",
    "reflectance_ground_truth = reflectance_ground_truth.view(1, channels, height, width)\n",
    "reflectance_ground_truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45271c",
   "metadata": {},
   "source": [
    "\n",
    "## PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e32110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psf_kernel(sigma=1.0, psf_size=15):\n",
    "\n",
    "    psf_kernel = torch.zeros(psf_size, psf_size)\n",
    "    psf_center = psf_size // 2\n",
    "    for x in range(psf_size):\n",
    "        for y in range(psf_size):\n",
    "            psf_kernel[x, y] = torch.exp(torch.tensor(-((x - psf_center) ** 2 + (y - psf_center) ** 2) / (2 * sigma ** 2)))\n",
    "    psf_kernel /= psf_kernel.sum()\n",
    "\n",
    "    return psf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e72ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_kernel = generate_psf_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793cf72",
   "metadata": {},
   "source": [
    "## CoordConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordConv2DLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        _, _, height, width = input_tensor.size()\n",
    "\n",
    "        # Create x and y coordinate grids\n",
    "        xx_channel = torch.arange(width).view(1, 1, 1, width).expand(1, 1, height, width).float() / (width - 1)\n",
    "        yy_channel = torch.arange(height).view(1, 1, height, 1).expand(1, 1, height, width).float() / (height - 1)\n",
    "\n",
    "        # Concatenate the coordinate channels to the input tensor\n",
    "        output_tensor = torch.cat([xx_channel, yy_channel], dim=1)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c94d32",
   "metadata": {},
   "source": [
    "## FourierConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierConv2DLayer(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, num_input_channels, height, width = x.size()\n",
    "\n",
    "        # Generate frequencies\n",
    "        base_frequency = 2\n",
    "        exponent_value = torch.arange(L)\n",
    "        frequencies = torch.pow(torch.tensor(base_frequency), exponent_value).float()\n",
    "\n",
    "        # Apply Fourier basis functions\n",
    "        fourier_features = [torch.sin(frequencies[j] * torch.pi * x) for j in range(L)]\n",
    "        fourier_features += [torch.cos(frequencies[j] * torch.pi * x) for j in range(L)]\n",
    "\n",
    "        # Concatenate the Fourier features along the channel dimension\n",
    "        fourier_features = torch.cat(fourier_features, dim=1)\n",
    "\n",
    "        return fourier_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eeeaed",
   "metadata": {},
   "source": [
    "## InverseConv2D Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseConv2DLayer(nn.Module):\n",
    "    def __init__(self, L, num_standard_layers, max_reflectance, subsample_factor=2, use_fourier=True):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "        self.num_fourier_channels = 2\n",
    "        self.num_standard_layers = num_standard_layers\n",
    "        self.use_fourier = use_fourier\n",
    "        \n",
    "        self.upsample_layer = nn.Upsample(scale_factor=subsample_factor, mode='nearest')\n",
    "        self.coordinate_layer = CoordConv2DLayer()\n",
    "        self.fourier_layer = FourierConv2DLayer(L)\n",
    "            \n",
    "        if self.use_fourier:\n",
    "            self.fourier_layer = FourierConv2DLayer(L)\n",
    "            self.num_fourier_channels = 4*L\n",
    "        \n",
    "        self.standard_hidden_layers = nn.ModuleList(\n",
    "        [nn.Conv2d(self.num_fourier_channels, self.num_fourier_channels, kernel_size=3, padding='same') for _ in range(num_standard_layers)]\n",
    "        )\n",
    "        \n",
    "        self.standard_output_layer = nn.Conv2d(self.num_fourier_channels, 1, kernel_size=3, padding='same')\n",
    "        self.downsample_layer = nn.MaxPool2d(kernel_size=subsample_factor, stride=subsample_factor)\n",
    "        \n",
    "        # Initialize weights with He uniform variance scaling initializer\n",
    "        for layer in self.standard_hidden_layers:\n",
    "            nn.init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "            nn.init.zeros_(layer.bias)  # Initialize biases to zero\n",
    "        nn.init.kaiming_uniform_(self.standard_output_layer.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        nn.init.zeros_(self.standard_output_layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample_layer(x)\n",
    "        output_coordinate = self.coordinate_layer(x)\n",
    "        \n",
    "        if self.use_fourier:\n",
    "            output_fourier = self.fourier_layer(output_coordinate)\n",
    "        else:\n",
    "            output_fourier = output_coordinate\n",
    "        \n",
    "        x = output_fourier\n",
    "        for layer in self.standard_hidden_layers:\n",
    "            x = nn.functional.elu(layer(x))\n",
    "        \n",
    "        output = nn.functional.softplus(self.standard_output_layer(x))\n",
    "        \n",
    "        use_sigmoidal_output = True\n",
    "        if use_sigmoidal_output:\n",
    "            output = max_reflectance * torch.sigmoid(output)\n",
    "        \n",
    "        output_downsampled = self.downsample_layer(output)\n",
    "        output_inverse = output_downsampled\n",
    "\n",
    "        #return output_coordinate, output_fourier, output_inverse\n",
    "        return output_coordinate, output_fourier, output, output_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a9c32",
   "metadata": {},
   "source": [
    "## Microscope Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34589880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroscopeCNNLayer(nn.Module):\n",
    "    def __init__(self, psf_kernel):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Conv2d(1, 1, kernel_size=psf_kernel.size(0), padding='same', bias=False)\n",
    "        self.conv_layer.weight = nn.Parameter(psf_kernel.unsqueeze(0).unsqueeze(0), requires_grad=False)\n",
    "        self.intensity_layer = IntensityLayer()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_conv = self.conv_layer(x)\n",
    "        output_intensity = self.intensity_layer(output_conv)\n",
    "        output_final = output_intensity / torch.max(output_intensity)\n",
    "        return output_conv, output_intensity, output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntensityLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.square(torch.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb381aa5",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a72739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, L, num_standard_layers, max_reflectance, subsample_factor, psf_kernel, use_fourier=True):\n",
    "        super().__init__()\n",
    "        self.inverse_layer = InverseConv2DLayer(L, num_standard_layers, max_reflectance, subsample_factor, use_fourier=use_fourier)\n",
    "        self.forward_layer = MicroscopeCNNLayer(psf_kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #output_coordinate, output_fourier, output_inverse = self.inverse_layer(x)\n",
    "        output_coordinate, output_fourier, output, output_inverse = self.inverse_layer(x)\n",
    "        output_conv, output_intensity, output_final = self.forward_layer(output_inverse)\n",
    "        \n",
    "        #return output_inverse, output_final\n",
    "        return output, output_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925717e6",
   "metadata": {},
   "source": [
    "## Sensor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_func(image, noise_level=0.1, subsample_factor=2):\n",
    "    # Generate random noise with the same shape as the input image\n",
    "    noise = noise_level * torch.randn_like(image)\n",
    "\n",
    "    # Add the scaled noise to the original image\n",
    "    noisy_image = image + noise\n",
    "    \n",
    "    # Apply subsampling using a pooling operation (e.g., MaxPool2d)\n",
    "    subsampled_image = nn.functional.max_pool2d(noisy_image, kernel_size=subsample_factor, stride=subsample_factor)\n",
    "    \n",
    "    # Clip the values to ensure they are within the valid range (0, 1)\n",
    "    sensor_image = torch.clamp(subsampled_image, 0, 1)\n",
    "\n",
    "    return sensor_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e24d9",
   "metadata": {},
   "source": [
    "## Generate \"Training\" Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model_mismatch = True\n",
    "if apply_model_mismatch:\n",
    "    psf_kernel_real = generate_psf_kernel(sigma=2.0, psf_size=21)\n",
    "    microscope_model_real = MicroscopeCNNLayer(psf_kernel_real)\n",
    "    _, _, training_image = microscope_model_real(reflectance_ground_truth)\n",
    "else:\n",
    "    microscope_model = MicroscopeCNNLayer(psf_kernel)\n",
    "    _, _, training_image = microscope_model(reflectance_ground_truth)\n",
    "\n",
    "subsample_factor = 2;\n",
    "apply_sensor = True\n",
    "if apply_sensor:\n",
    "    training_image = sensor_func(training_image, subsample_factor = subsample_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6167a3",
   "metadata": {},
   "source": [
    "## Visualize Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40582578",
   "metadata": {},
   "source": [
    "### Image Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ce28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_plot = reflectance_ground_truth.squeeze().numpy()\n",
    "training_image_plot = training_image.squeeze().numpy()\n",
    "\n",
    "fig, (ax_1, ax_2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "fig.suptitle(\"Visualize Inputs\")\n",
    "\n",
    "ax_1.imshow(ground_truth_plot, cmap='gray')\n",
    "ax_1.set_xlabel('X-coordinate of pixel')\n",
    "ax_1.set_ylabel('Y-coordinate of pixel')\n",
    "ax_1.set_title('Ground Truth')\n",
    "\n",
    "ax_2.imshow(training_image_plot, cmap='gray')\n",
    "ax_2.set_xlabel('X-coordinate of pixel')\n",
    "ax_2.set_ylabel('Y-coordinate of pixel')\n",
    "ax_2.set_title('Training Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ground_truth_plot, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, yt = torch.meshgrid(torch.arange(training_image_plot.shape[0]), torch.arange(training_image_plot.shape[1]))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xt, yt, training_image_plot, cmap='viridis', alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Training Image Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e497d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_positive_plot = training_image_positive.squeeze().detach().numpy()\n",
    "plt.imshow(training_image_positive_plot, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a605a",
   "metadata": {},
   "source": [
    "### Surface Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Surface plot of the Training Image\")\n",
    "\n",
    "ax_1 = fig.add_subplot(111, projection='3d')\n",
    "surface = ax_1.plot_surface(xt, yt, training_image_plot, cmap='viridis')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Surface plot of the Ground Truth\")\n",
    "\n",
    "ax_1 = fig.add_subplot(111, projection='3d')\n",
    "surface = ax_1.plot_surface(xp, yp, ground_truth_plot, cmap='viridis')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefd87e",
   "metadata": {},
   "source": [
    "## Check size of Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713323d",
   "metadata": {},
   "source": [
    "## Define configurations for Inverse Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 4\n",
    "num_standard_layers = 4\n",
    "max_reflectance = alpha\n",
    "use_fourier = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461bd058",
   "metadata": {},
   "source": [
    "## Network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a185b1",
   "metadata": {},
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dde989",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn_model_dummy = PINN(L, num_standard_layers, max_reflectance, subsample_factor, psf_kernel, use_fourier)\n",
    "_, channels_dummy, height_dummy, width_dummy = training_image.size()\n",
    "summary(pinn_model_dummy, input_size=(channels_dummy, height_dummy, width_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PINN model\n",
    "pinn_model = PINN(L, num_standard_layers, max_reflectance, subsample_factor, psf_kernel, use_fourier)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(pinn_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Set up the exponential learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=np.exp(np.log(5e-6 / 1e-4) / 10000))\n",
    "\n",
    "# Set the regularization strengths (lambdas)\n",
    "lambda_boundary = 0.25\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10000\n",
    "\n",
    "# Define list to store loss values\n",
    "loss_list = []\n",
    "\n",
    "# Define list to store intermediate outputs for reflectance\n",
    "intermediate_output_reflectance = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    _, iter_image = pinn_model(training_image)\n",
    "\n",
    "    # Calculate the mse loss\n",
    "    loss_mse = criterion(iter_image, training_image)\n",
    "    \n",
    "    # Calculate the boundary regularization loss\n",
    "    loss_boundary = lambda_boundary * (\n",
    "          torch.square(iter_image[:, :, 0, :] - 0).mean()\n",
    "        + torch.square(iter_image[:, :, -1, :] - 0).mean()\n",
    "        + torch.square(iter_image[:, :, :, 0] - 0).mean()\n",
    "        + torch.square(iter_image[:, :, :, -1] - 0).mean()\n",
    "    )\n",
    "    \n",
    "    # Calculate the total loss\n",
    "    use_boundary_loss = True\n",
    "    if use_boundary_loss:\n",
    "        loss_total = loss_mse + loss_boundary\n",
    "    else:\n",
    "        loss_total = loss_mse\n",
    "    loss = loss_total\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print training statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd62dc4",
   "metadata": {},
   "source": [
    "## Display Loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1230d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4e886",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reflectance, predicted_image = pinn_model(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0197c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reflectance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b050b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481f8bb",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reflectance_plot = predicted_reflectance.squeeze().detach().numpy()\n",
    "\n",
    "fig, (ax_1, ax_2, ax_3) = plt.subplots(1, 3, figsize=(16, 6))\n",
    "fig.suptitle(\"Visualize Reflectance\")\n",
    "\n",
    "ax_1.imshow(ground_truth_plot, cmap='gray')\n",
    "ax_1.set_ylabel('Y-coordinate')\n",
    "ax_1.set_title('Ground Truth')\n",
    "\n",
    "ax_2.imshow(training_image_plot, cmap='gray')\n",
    "ax_2.set_xlabel('X-coordinate')\n",
    "ax_2.set_title('Training Image')\n",
    "\n",
    "ax_3.imshow(predicted_reflectance_plot, cmap='gray')\n",
    "ax_3.set_title('PINN Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_1, ax_2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(\"Visualize Reflectance\")\n",
    "\n",
    "ax_1.imshow(ground_truth_plot, cmap='gray')\n",
    "ax_1.set_ylabel('Y-coordinate')\n",
    "ax_1.set_title('Ground Truth')\n",
    "\n",
    "ax_2.imshow(predicted_reflectance_plot, cmap='gray')\n",
    "ax_2.set_xlabel('X-coordinate')\n",
    "ax_2.set_title('PINN Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr, yr = torch.meshgrid(torch.arange(predicted_reflectance_plot.shape[0]), torch.arange(predicted_reflectance_plot.shape[1]))\n",
    "\n",
    "fig= plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Surface plot of the Prediction\")\n",
    "\n",
    "ax_1 = fig.add_subplot(111, projection='3d')\n",
    "surface = ax_1.plot_surface(xr, yr, predicted_reflectance_plot, cmap='viridis')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predicted_reflectance_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3119525",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reflectance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectance_ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702cd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_reflectance_plot, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a842639",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_image_plot, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
